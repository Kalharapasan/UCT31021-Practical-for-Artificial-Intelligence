# -*- coding: utf-8 -*-
"""UCT31021-Lab11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yfGSdPV2cYTpKpWOWQNvmJRKFDBCNDxp

**Task:01**

**01.What is panda?**

Panda is a powerful python library for data manipulation and analysis. It provides an easy to use data structure which are series & dataframes.
"""

import pandas as pd

"""02.Create Series in pandas.

"""

s= pd.Series([10,20,30,40],index=['a','b','c','d'])
print(f"Series is \n{s}")

"""**03.Creating Dataframe in pandas.**"""

data = {'Name':['Alice','Bob'],'Age':[25,30]}
df = pd.DataFrame(data)
print(f"Dataframe is \n{df}")

"""**04.Data saving in Excel.**"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install openpyxl

from google.colab import files

df = pd.DataFrame(df)
df.to_excel('data.xlsx', index=False)
files.download('data.xlsx')

# Commented out IPython magic to ensure Python compatibility.
# Step 1: Install openpyxl (for Excel support)
# %pip install -q openpyxl
# Step 2: Import necessary libraries
import pandas as pd
from google.colab import files

# Step 3: Create sample DataFrame
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 28],
    'Department': ['AI', 'ML', 'DS', 'AI'],
    'Score': [85, 90, 88, 92]
}
df = pd.DataFrame(data)
# Step 4: Save to Excel
df.to_excel('data.xlsx', index=False)
# Step 5: Download the Excel file
files.download('data.xlsx')

"""**05Dataframe Operations**

i.View First row
"""

from google.colab import files
uploaded = files.upload()

df = pd.read_excel('data.xlsx', engine='openpyxl')

print(df.head(1))

"""ii.View Last row"""

print(df.tail(1))

"""iii.View dataframe info"""

print(df.info())

"""iv.View dataframe description"""

print(df.describe())

"""v.Selecting, Filtering, select by label (already finished)"""

print(df[df['Age'] > 28])
print(df.loc[0])

"""**06.Create Dataframe with missing values.**"""

import numpy as np

data_with_nan = {
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, np.nan, 35]
}
df_nan = pd.DataFrame(data_with_nan)
print(df_nan)

"""07.**Handling missing value using Pandas**

i.Drop missing value
"""

print(df_nan.dropna())

"""ii.Fill missing values"""

print(df_nan.fillna(0))

"""iii.Interpolation"""

print(df_nan.interpolate())

"""**08.Data Transformation**

i.Renaming Columns
"""

df_renamed = df.rename(columns={'Name': 'Full Name'})
print(df_renamed)

"""ii.Changing Data Types"""

df['Age'] = df['Age'].astype(float)
print(df.dtypes)

"""iii.Creating or Modifying Column"""

df['Age in 5 Years'] = df['Age'] + 5
print(df)

"""**Task:02**

**01.Random Dataset Creation**
"""

import pandas as pd
import numpy as np

# Set seed for reproducibility
np.random.seed(54)

# Number of rows
n = 100

# Create a DataFrame with synthetic data
data = {
    'ID': range(1, n + 1),
    'Name': np.random.choice(['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'], size=n),
    'Age': np.random.randint(18, 65, size=n).astype(float),  # Use float for missing values
    'Salary': np.random.randint(30000, 100000, size=n).astype(float),
    'Department': np.random.choice(['HR', 'IT', 'Finance', 'Marketing', 'Operations'], size=n),
    'JoinDate': pd.date_range(start='2020-01-01', periods=n, freq='D')
}

df_big = pd.DataFrame(data)

# Introduce missing values randomly in a few columns (10% missing rate per column)
for col in ['Name', 'Age', 'Salary', 'Department']:
    df_big.loc[df_big.sample(frac=0.1).index, col] = np.nan

print(df_big.head(10))

df_big.info()

df_big.describe(include='all')

"""**02.Check missing value**"""

# Check for missing values
df_big.isnull().sum()

"""**03.Handling missing Data**"""

df_big[['Age', 'Salary']] = df_big[['Age', 'Salary']].interpolate()
df_big['Salary'] = df_big['Salary'].bfill()

print(df_big)

df_big['Name'] = df_big['Name'].ffill()
df_big['Department'] = df_big['Department'].fillna(df_big['Department'].mode()[0])

print(df_big)

"""**04.Transform your Data**"""

df['Grade'] = pd.cut(df['Score'], bins=[0, 60, 75, 90, 100],
                     labels=['Poor', 'Average', 'Good', 'Excellent'])
print(df)

#Rename Columns:
df_big.rename(columns={'Name': 'Employee Name'}, inplace=True)

df_big['Age'] = df_big['Age'].astype(int)
df_big['Salary'] = df_big['Salary'].astype(float)

print(df_big)

#create New Columns
df_big['Bonus Salary'] = df_big['Salary']*1.10
print (df_big)

print(df_big.head(10))

"""**05.Combining & Merging Dataframes**"""

df2 = pd.DataFrame({
    'ID': [11, 12],
    'Name': ['Kate', 'Leo'],
    'Department': ['AI', 'DS'],
    'Score': [82, 76]
})

print(df2)

"""I.Concatenation"""

df_concat = pd.concat([df, df2], ignore_index=True)
print(df_concat)

"""II.Merging"""

df_scores = pd.DataFrame({'ID': [1, 2, 3], 'Bonus': [5, 10, 8]})
df_merged = pd.merge(df, df_scores, on='ID', how='left')
print(df_merged)

"""II.Joining"""

df_a = df.set_index('ID')
df_b = df_scores.set_index('ID')
df_joined = df_a.join(df_b)
df_joined.reset_index()

print(df_joined)

"""**05.Group Data**

I.Iterate over groups
"""

grouped = df.groupby('Department')
for name, group in grouped:
    print(f"Group: {name}")
    print(group)

"""II.Apply Aggregation"""

df.groupby('Department')['Score'].mean()

"""**07.Calculating Summary Statistics for Group Data**

I.Aggregation using groupby
"""

df.groupby('Department').agg({
    'Score': ['mean', 'max', 'min']
})

"""II.Aggregation using pivot_table"""

df.pivot_table(values='Score', index='Department', aggfunc='mean')

"""III.Custom Aggregation using .agg()"""

df.groupby('Department').agg(
    Score_Mean=('Score', 'mean'),
    Count=('Score', 'count'),
    Std_Dev=('Score', 'std')
)